<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on Kenneth Lee</title>
    <link>https://kenneth-lee-ch.github.io/tags/statistics/</link>
    <description>Recent content in Statistics on Kenneth Lee</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2020 Kenneth Lee</copyright>
    <lastBuildDate>Sat, 12 Dec 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://kenneth-lee-ch.github.io/tags/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Impact of Inteventions seen through mobility</title>
      <link>https://kenneth-lee-ch.github.io/project/covid19/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kenneth-lee-ch.github.io/project/covid19/</guid>
      <description>&lt;p&gt;Based on assumptions, we have found that state-wide government interventions tend to have a larger effect in reducing mobility in the areas with a large population, a small percentage of people in poverty, a high percent of people with education backgrounds, and a low unemployment rate.&lt;/p&gt;

&lt;p&gt;Secondly, recommended polcies, gathering restriction and school closure, may not have a sigificant effect in reducing mobility, whereas some mandatory policies such as public masks and business closures have a significant effect on mobility in California counties. We rank the effectiveness of the intervention on mobility in terms of the regression coefficient in a linear regression setting. Other regression methods should also be used for further study.&lt;/p&gt;

&lt;p&gt;In future, we need to collect more data about county-level intervention to measure the start dates and end dates of the policies more accurately. Also, we can examine other mobility signals available in the Dephi API.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Student/Teacher Achievement Ratio</title>
      <link>https://kenneth-lee-ch.github.io/project/star/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kenneth-lee-ch.github.io/project/star/</guid>
      <description>&lt;p&gt;The effects of class sizes on student achievement is an important topic for policymakers in the American K-12 education system. To study the effects of class size on student achievement in the primary grades, the State Department of Education in Tennessee launched a four-year longitudinal class-size randomized study from 1985 to 1989 called The Student/Teacher Achievement Ratio (STAR). Over 7000 students in 79 schools participated in this project. We highlight the features of the experiment process in the study below.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;All participating schools had to agree to the random assignment of teachers and students to different class conditions: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher’s aide).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The assignments of various class types were initiated as the students entered school in kindergarten and continued through third grade.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Each school must provide enough kindergarten students to be assigned to three numerous class types in order to participate in the project STAR.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The student achievement is measured annually via Stanford Achievement Tests (SATs) during the spring term on testing dates specified by the Tennessee state.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Students moving from a school involved in STAR to another participating school were assigned to the same type of class as they had participated in previously. Also, it is possible that the size of a regular class can be as small as the small class type as students move out of the participating schools.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Besides class size and teacher aides, there were no other experimental changes involved in the study.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;There were three schools resigned from the project STAR at the end of kindergarten, so that there were only left with 76 schools in the 1st-grade level.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our primary scientific question of interest is whether there is a treatment effect of assigning various class types to the average math scaled scores in a 1st-grade class level. We implement exploratory data analysis, two-way ANOVA model, model diagnostics, hypothesis testing. In the end, we will discuss any causal statements that could possibly be made based on our analysis and assumptions and the differences between a student-level and a class-level analysis on this STAR dataset.&lt;/p&gt;

&lt;p&gt;This work shows that the treatment effect of the class type does exist in a class level for this dataset. We also show that it is possible to make causal statements based on our analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Heart Disease Classification</title>
      <link>https://kenneth-lee-ch.github.io/project/heart/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kenneth-lee-ch.github.io/project/heart/</guid>
      <description>

&lt;p&gt;In this project, we aim to train a classifier to accurately classify a person whether or not has a heart disease problem. In particular, we would like to compare several classification algorithms: logistic regression, random forests, support vector machine and k-nearest neighbours based on sensitivity and classification accuracy. Also, it will be beneficial to see if we can reduce the number of features to perform a good classification that may potentially lower the costs of collecting expensive features in the future. Most people believe that age should be a strong indicator whether a person has a heart disease problem. Our project will also validate this claim and see if there are any better indicators with hypothesis testing.&lt;/p&gt;

&lt;h2 id=&#34;questions-of-interests&#34;&gt;Questions of interests&lt;/h2&gt;

&lt;p&gt;What is the relationship between age and heart disease?&lt;/p&gt;

&lt;p&gt;Will combining several predictors into one new predictor variable be useful to improve our model?&lt;/p&gt;

&lt;p&gt;What will be the best combination of features we should use based on the classification algorithm?&lt;/p&gt;

&lt;p&gt;Can we reduce the number of features and still get a satisfactory classification performance?&lt;/p&gt;

&lt;p&gt;What is the best classification rate that we can come up with to predict the presence of heart disease?&lt;/p&gt;

&lt;h2 id=&#34;data-exploration&#34;&gt;Data Exploration&lt;/h2&gt;

&lt;p&gt;We first explore the data by making use of boxplots, histograms, density plots, and a scatterplot matrix. In particular, we use boxplots to explore the distribution of some quantitative variables such as maximum heart rate achieved, serum cholesterol, age, resting blood pressure and by gender and disease to see if there is any significant differences among different genders and types of disease.&lt;/p&gt;

&lt;p&gt;Then, we would split the data set into training and testing datasets by having 80 percent of the data to be training and 20 percent of the data to be testing. We then implemented several algorithms including logistic regression, random forests, support vector machine, and K-nearest neighbors to classify the presence and absence of heart disease. We also conduct outlier detection to see if there is a performance gain by dropping some potential outliers in the data.&lt;/p&gt;

&lt;h2 id=&#34;classification-model&#34;&gt;Classification Model&lt;/h2&gt;

&lt;h3 id=&#34;logistic-regression&#34;&gt;Logistic Regression&lt;/h3&gt;

&lt;p&gt;We first compare two logistic models that use all the predictor variables: model 1 and model 2. The difference between these two models is that we dropped two potential outliers (row 259 and 4) by looking at the standardized deviance residual plot and use the rest of the data to train the model 2 to see if there is a performance gain in comparison with model 1.&lt;/p&gt;

&lt;p&gt;Next, we also train three logistic regression models with different numbers of predictors. Model 3 utilizes all first order term and two-way interaction term. Model 4 is only trained with quantitative predictor variables including age, resting blood pressure, serum cholesterol, maximum heart rate achieved, oldpeak, and major vessels. Model 5 will be trained by a reduced number of features based on our feature selection method. Then, we will select the model with the highest accuracy and sensitivity rate to compare with other algorithms.&lt;/p&gt;

&lt;h4 id=&#34;probability-threshold-selction-for-logistic-regression-classification&#34;&gt;Probability threshold selction for logistic regression classification&lt;/h4&gt;

&lt;p&gt;Besides, we use Receiver Operating Characteristics (ROC) curve to see what are some best cut-off threshold for getting the most accurate classification rate for each model by picking thresholds that maximizes the area under the curve as it measures how good our model is able to distinguish two classes of the response variable.&lt;/p&gt;

&lt;h4 id=&#34;features-selection&#34;&gt;Features selection&lt;/h4&gt;

&lt;p&gt;We want to estimate the variable importance to see if we can reduce the number of features and still achieve a satisfactory result. The importance can be estimated using a ROC curve analysis conducted for each attribute.&lt;/p&gt;

&lt;h2 id=&#34;evaluation-metric&#34;&gt;Evaluation Metric&lt;/h2&gt;

&lt;p&gt;Our evaluation metric is based on sensitivity and the accuracy rate. Since it is more important to
correctly identify people who have a heart disease, we set the presence of heart disease as positive. Sensitivity is the true positive rate, which is the percentage of people with heart disease who are correctly identified as having the condition.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In conclusion, we see people who have heart disease are mostly around the age of 60. Also, the predictor variable, age, doesn’t explain the response variable of heart disease as good as the number of major vessels in our logistic regression model. Moreover, we see that combining features into one predictor variable by using two-way interaction terms does not necessarily improve classification performance in general. When we look at our logistic regression models, we see that reducing number of features for training can improve model performance by excluding the predictor named fasting blood sugar. We have found that the following predictors are particularly important in logistic regression model for classification: major vessels, chest pain type, thal, sex, resting blood pressure, slope, oldpeak, serum cholestoral, exercise induced angina and maximum heart rate achieved.&lt;/p&gt;

&lt;h2 id=&#34;data-source&#34;&gt;Data Source&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://archive.ics.uci.edu/ml/datasets/statlog+(heart)&#34; target=&#34;_blank&#34;&gt;UCI heart disease data set&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
