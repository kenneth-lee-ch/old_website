<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Neural Networks on Kenneth Lee</title>
    <link>https://kenneth-lee-ch.github.io/tags/neural-networks/</link>
    <description>Recent content in Neural Networks on Kenneth Lee</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2020 Kenneth Lee</copyright>
    <lastBuildDate>Fri, 12 Jun 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://kenneth-lee-ch.github.io/tags/neural-networks/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>What2Cook</title>
      <link>https://kenneth-lee-ch.github.io/project/what2cook/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kenneth-lee-ch.github.io/project/what2cook/</guid>
      <description>&lt;p&gt;We explore the potential of creating new recipes via text data. Our goal has two folds. First, we aim to classify the cuisine based on ingredients. Second, we want to predict an ingredient that is missing from a given list of ingredients and a cuisine name. The first task can be formulated as a multi-class classification problem. To convert the text into numerical signals, we can use TFIDF vectorizer, Countvectorizer, word embedding based on Word2Vec model. We are able to achieve 0.85 micro-averaged F1 scores for the multi-classification task with multilayer perceptrons and bag-of-words model.&lt;/p&gt;

&lt;p&gt;For the first task, we compare several well-known classification algorithms such as logistic regression, naive bayes, linear discriminant analysis, decision tree classifier, random forest, Adaboost, multi-layer perceptrons. We conduct grid search with 5-fold stratified cross-validation for hyperparameter tuning.&lt;/p&gt;

&lt;p&gt;For the second task, we adopt two approaches to process the recipe text, which is the key to the recommender system. We first explore the recommended ingredients based on similarity to the given recipe using vectorizers; and then we examine the performance, in terms of the &amp;ldquo;top n accuracy&amp;rdquo; metric, of a baseline popularity model and a sophiticated collaborative filtering model under the ``text_preprocess method.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Credit Card Fraud Detection</title>
      <link>https://kenneth-lee-ch.github.io/project/creditfraud/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kenneth-lee-ch.github.io/project/creditfraud/</guid>
      <description>&lt;p&gt;Credit card fraud detection is one of the most important issues for credit card companies to deal with in order to earn trust from its customers. As machine learning techniques are robust to many tackle classification problems settings such as image recognition, we aim to explore various machine learning classification algorithms on this particular problem of classifying credit card fraud.&lt;/p&gt;

&lt;p&gt;This work showcases on how to compare different algorithms and fine-tune them. The dataset mainly contains 492 frauds out of 284,807 transactions. It has 28 principle components, transaction time, and tranaction amount with labels, 0 being non-fraud and 1 being fraud.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SMS Spam Classification</title>
      <link>https://kenneth-lee-ch.github.io/project/spam/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kenneth-lee-ch.github.io/project/spam/</guid>
      <description>&lt;p&gt;Spam, a bulk of unsolicited messages sent by anonymous sources, has been a costly issue to human communication. Machine learning techniques have been shown promising to filter these messages as it adapts to the evolving characteristics of the spam. In this work, we focus on neural networks to the problem of spam filtering. Overall, we conclude that using bidirectioncomparing various classification methodsal gated recurrent neural network with tokenizer method is the most robust way we have found to handle this problem with our particular dataset. This work provides insights on how to design a neural network to work with spam filtering problem as part of my contribution to a course project titled &amp;ldquo;Machine_Learning_Approaches_to_Spam_Filtering_Problems&amp;rdquo;. You may click on the PDF file to view the full paper.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Meet Don, the Autonomous Dice Rolling Machine</title>
      <link>https://kenneth-lee-ch.github.io/project/dicemachine/</link>
      <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kenneth-lee-ch.github.io/project/dicemachine/</guid>
      <description>&lt;p&gt;We estimated probabilities for tetrahedral and triangular dice using the sphere projection method and multivariate calculus. To test our results, we printed several dice of varying sizes. After a few thousand initial rolls, we realized that our calculations werenâ€™t accurately describing the situation and that bias could have been introduced due to rolling the dice by hand. Therefore, we built a machine to roll the dice.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
